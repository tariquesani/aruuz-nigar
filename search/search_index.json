{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Aruuz Nigar - Urdu Poetry Scansion Tool What is Aruuz Nigar? Aruuz Nigar is an Urdu poetry scansion tool that helps poets and readers understand Urdu ar\u016bz by inferring the taqti of individual lines and matching them against known bahrs. It consists of two parts: Aruuz , a reusable Python library that performs the scansion and meter analysis, and Nigar , a Flask based web frontend that provides a basic interface for end-users. Why create Aruuz Nigar? Aruuz Nigar was created for my understanding of Urdu ar\u016bz. While tools such as Rekhta's taqti and Aruuz.com are available, Rekhta is proprietary and the publicly available Aruuz.com codebase is more than a decade old, written in C#. Aruuz Nigar aims to provide a modern, open source, developer friendly alternative with a clear semantic core that can run on both desktops and servers. How to use Aruuz Nigar? Download for Windows end-users Download the executable server file from [Coming Soon], Unzip it in a folder. Double click on aruuznigar.exe . A browser with the Web interface will launch, if it doesn't, open 127.0.0.1:5000 in your browser. Note : The Windows executable runs a local Flask web server and opens the interface in your browser. All processing happens locally on your machine, and no external network access is required. For everyone else Installation: Clone the repository: git clone https://github.com/tariquesani/aruuz-nigar.git cd aruuz-nigar/ Setup Virtual Environment Windows: python -m venv venv venv \\S cripts \\a ctivate pip install --upgrade pip pip install -e . pip install -r requirements.txt Linux/Mac: python3 -m venv venv source venv/bin/activate pip install --upgrade pip pip install -e . pip install -r requirements.txt Run the Flask web application (Nigar): python app.py Then open your browser to: http://127.0.0.1:5000 The web app provides: - RTL (right-to-left) text input for Urdu poetry - RTL display of scansion codes - Meter matching and identification For developers, use as a Python library (Aruuz): from aruuz.scansion import Scansion from aruuz.models import Lines scanner = Scansion () line = Lines ( \"\u0646\u0642\u0634 \u0641\u0631\u06cc\u0627\u062f\u06cc \u06c1\u06d2 \u06a9\u0633 \u06a9\u06cc \u0634\u0648\u062e\u06cc\u0650 \u062a\u062d\u0631\u06cc\u0631 \u06a9\u0627\" ) scanner . add_line ( line ) results = scanner . scan_lines () Project Structure aruuz/ - Main package (Aruuz library) scansion/ - Core scansion engine modules core.py - Main scansion engine word_analysis.py - Word-level analysis word_scansion_assigner.py - Word scansion assignment code_assignment.py - Code assignment logic length_scanners.py - Length scanning functions meter_matching.py - Meter matching algorithms prosodic_rules.py - Prosodic rules and adjustments scoring.py - Scoring mechanisms explanation_builder.py - Explanation generation tree/ - Pattern matching trees code_tree.py - Code tree implementation pattern_tree.py - Pattern tree matching state_machine.py - State machine for pattern matching database/ - Database functionality word_lookup.py - Word lookup from database aruuz_nigar.db - SQLite database utils/ - Utility functions text.py - Text processing utilities araab.py - Diacritical marks handling logging_config.py - Logging configuration meters.py - Meter definitions (bahrs) models.py - Data models (Lines, Words, etc.) app.py - Flask web application (Nigar frontend) templates/ - Flask HTML templates index.html - Main interface static/ - Static web assets (CSS, etc.) scripts/ - CLI scripts and utilities scan_poetry.py - Poetry scanning script scan_word.py - Word scanning script tests/ - Test suite legacy/ - Legacy test files test_canonical_sher_to_bahr_mapping.py - Canonical test mappings docs/ - Documentation files setup.py - Package setup configuration requirements.txt - Python dependencies Notes Word-level scansion intentionally over-generates. Canonical selection happens at line/meter level. Attribution Based on the original Aruuz by Sayed Zeeshan Asghar (thank you!) Original: GPL-2.0 licensed Aruuz Nigar Python port: GPL-3.0 licensed Ported by Dr. Tarique Sani, 2026 Status In Development - Works well for regular meters (bahr) - Will work with some caveats for bahr-e-hindi and bahr-e-zamzama - Does not support Rubai well Bug Reports and Feedback very welcome Aruuz Nigar is under active development, and bugs or incorrect scansion results are expected. If you encounter issues, please report them using GitHub Issues . Documentation The core Python library ( aruuz/ ) is extensively documented using module-level docstrings and inline explanations for all public classes and functions. These docstrings describe the intended behavior, inputs, outputs, and design rationale of the scansion engine, meter matching, tree traversal, scoring, and utility modules. The existing source documentation is suitable for automatic API documentation generation using tools such as Sphinx or similar docstring-based systems. Generated API documentation is not published yet and will be added once the public interfaces stabilize further. License GPL V3.0, See LICENSE file in parent directory.","title":"Home"},{"location":"#aruuz-nigar-urdu-poetry-scansion-tool","text":"","title":"Aruuz Nigar - Urdu Poetry Scansion Tool"},{"location":"#what-is-aruuz-nigar","text":"Aruuz Nigar is an Urdu poetry scansion tool that helps poets and readers understand Urdu ar\u016bz by inferring the taqti of individual lines and matching them against known bahrs. It consists of two parts: Aruuz , a reusable Python library that performs the scansion and meter analysis, and Nigar , a Flask based web frontend that provides a basic interface for end-users.","title":"What is Aruuz Nigar?"},{"location":"#why-create-aruuz-nigar","text":"Aruuz Nigar was created for my understanding of Urdu ar\u016bz. While tools such as Rekhta's taqti and Aruuz.com are available, Rekhta is proprietary and the publicly available Aruuz.com codebase is more than a decade old, written in C#. Aruuz Nigar aims to provide a modern, open source, developer friendly alternative with a clear semantic core that can run on both desktops and servers.","title":"Why create Aruuz Nigar?"},{"location":"#how-to-use-aruuz-nigar","text":"","title":"How to use Aruuz Nigar?"},{"location":"#download-for-windows-end-users","text":"Download the executable server file from [Coming Soon], Unzip it in a folder. Double click on aruuznigar.exe . A browser with the Web interface will launch, if it doesn't, open 127.0.0.1:5000 in your browser. Note : The Windows executable runs a local Flask web server and opens the interface in your browser. All processing happens locally on your machine, and no external network access is required.","title":"Download for Windows end-users"},{"location":"#for-everyone-else","text":"Installation: Clone the repository: git clone https://github.com/tariquesani/aruuz-nigar.git cd aruuz-nigar/ Setup Virtual Environment Windows: python -m venv venv venv \\S cripts \\a ctivate pip install --upgrade pip pip install -e . pip install -r requirements.txt Linux/Mac: python3 -m venv venv source venv/bin/activate pip install --upgrade pip pip install -e . pip install -r requirements.txt Run the Flask web application (Nigar): python app.py Then open your browser to: http://127.0.0.1:5000 The web app provides: - RTL (right-to-left) text input for Urdu poetry - RTL display of scansion codes - Meter matching and identification For developers, use as a Python library (Aruuz): from aruuz.scansion import Scansion from aruuz.models import Lines scanner = Scansion () line = Lines ( \"\u0646\u0642\u0634 \u0641\u0631\u06cc\u0627\u062f\u06cc \u06c1\u06d2 \u06a9\u0633 \u06a9\u06cc \u0634\u0648\u062e\u06cc\u0650 \u062a\u062d\u0631\u06cc\u0631 \u06a9\u0627\" ) scanner . add_line ( line ) results = scanner . scan_lines ()","title":"For everyone else"},{"location":"#project-structure","text":"aruuz/ - Main package (Aruuz library) scansion/ - Core scansion engine modules core.py - Main scansion engine word_analysis.py - Word-level analysis word_scansion_assigner.py - Word scansion assignment code_assignment.py - Code assignment logic length_scanners.py - Length scanning functions meter_matching.py - Meter matching algorithms prosodic_rules.py - Prosodic rules and adjustments scoring.py - Scoring mechanisms explanation_builder.py - Explanation generation tree/ - Pattern matching trees code_tree.py - Code tree implementation pattern_tree.py - Pattern tree matching state_machine.py - State machine for pattern matching database/ - Database functionality word_lookup.py - Word lookup from database aruuz_nigar.db - SQLite database utils/ - Utility functions text.py - Text processing utilities araab.py - Diacritical marks handling logging_config.py - Logging configuration meters.py - Meter definitions (bahrs) models.py - Data models (Lines, Words, etc.) app.py - Flask web application (Nigar frontend) templates/ - Flask HTML templates index.html - Main interface static/ - Static web assets (CSS, etc.) scripts/ - CLI scripts and utilities scan_poetry.py - Poetry scanning script scan_word.py - Word scanning script tests/ - Test suite legacy/ - Legacy test files test_canonical_sher_to_bahr_mapping.py - Canonical test mappings docs/ - Documentation files setup.py - Package setup configuration requirements.txt - Python dependencies","title":"Project Structure"},{"location":"#notes","text":"Word-level scansion intentionally over-generates. Canonical selection happens at line/meter level.","title":"Notes"},{"location":"#attribution","text":"Based on the original Aruuz by Sayed Zeeshan Asghar (thank you!) Original: GPL-2.0 licensed Aruuz Nigar Python port: GPL-3.0 licensed Ported by Dr. Tarique Sani, 2026","title":"Attribution"},{"location":"#status","text":"In Development - Works well for regular meters (bahr) - Will work with some caveats for bahr-e-hindi and bahr-e-zamzama - Does not support Rubai well Bug Reports and Feedback very welcome Aruuz Nigar is under active development, and bugs or incorrect scansion results are expected. If you encounter issues, please report them using GitHub Issues .","title":"Status"},{"location":"#documentation","text":"The core Python library ( aruuz/ ) is extensively documented using module-level docstrings and inline explanations for all public classes and functions. These docstrings describe the intended behavior, inputs, outputs, and design rationale of the scansion engine, meter matching, tree traversal, scoring, and utility modules. The existing source documentation is suitable for automatic API documentation generation using tools such as Sphinx or similar docstring-based systems. Generated API documentation is not published yet and will be added once the public interfaces stabilize further.","title":"Documentation"},{"location":"#license","text":"GPL V3.0, See LICENSE file in parent directory.","title":"License"},{"location":"api/","text":"Auto-generated API documentation will live here.","title":"API Documentation"},{"location":"guides/ambiguity/","text":"Ambiguity in Aruuz Nigar This document is intended to clarify interpretation of results rather than engine mechanics. Purpose of This Document Explain why ambiguity is inherent in Urdu ar\u016bz Clarify how and where ambiguity arises in Aruuz Nigar Distinguish expected ambiguity from genuine limitations Help users interpret results correctly and confidently Why Ambiguity Exists in Urdu Ar\u016bz Urdu ar\u016bz is based on pronunciation, not spelling Pronunciation varies by context, convention, and reader Classical prosody allows multiple valid readings of the same line Ambiguity is a property of the poetic system, not a computational artifact Ambiguity as a Design Principle Aruuz Nigar treats ambiguity as meaningful information The engine avoids forcing early decisions Multiple interpretations are preserved where rules permit Certainty is introduced only when structural evidence is sufficient Types of Ambiguity Encountered Lexical Ambiguity (Word-Level) A single word may admit multiple syllabic patterns Dictionary entries may contain variants Heuristic analysis may produce multiple valid outcomes Word-level ambiguity is common and expected Contextual Ambiguity (Inter-Word) Pronunciation may change based on neighboring words Classical prosodic rules introduce conditional variations Word joins and elisions can produce alternate rhythmic paths Contextual ambiguity may increase, not decrease, possibilities Metrical Ambiguity (Line-Level) A complete rhythmic pattern may fit more than one meter Closely related meters may share structural prefixes Multiple meters may remain valid even after full analysis This reflects classical overlap, not analytical failure How Aruuz Nigar Handles Ambiguity Intentional Over-Generation The engine generates all plausible scansion possibilities No valid interpretations are discarded prematurely Over-generation ensures completeness of analysis Constraint-Driven Pruning Invalid interpretations are eliminated by meter constraints Pruning occurs gradually as structure accumulates Only interpretations that violate prosodic rules are removed Late Resolution Ambiguity is resolved only after full line or multi-line context Word-level uncertainty is evaluated at meter level Decisions are postponed until meaningful comparison is possible Dominant Bahr and Ambiguity What \u201cDominant\u201d Means Dominance is a scoring-based preference It reflects consistency across related lines It does not imply absolute correctness What Dominant Does Not Mean It does not mean alternate meters are wrong It does not eliminate all ambiguity in interpretation It does not override classical permissibility When Ambiguity Is Expected Classical poetry with flexible pronunciation Lines with optional joins or elisions Meters with overlapping structural forms Words with well-known variant readings When Ambiguity May Indicate a Limitation Rare or highly dialectal vocabulary Modern poetic forms outside classical ar\u016bz Incomplete lexical coverage Known unsupported or weakly supported meters How Users Should Interpret Results Multiple results should be read as interpretive space Human judgment remains essential in choosing among alternatives Consistency across lines is more significant than isolated matches Ambiguity should be explored, not dismissed Common Misconceptions \u201cMore results mean lower confidence\u201d False: multiple results often indicate legitimate flexibility \u201cThere must be exactly one correct scansion\u201d False: classical ar\u016bz permits multiple valid readings \u201cDominant bahr is the only correct answer\u201d False: dominance reflects preference, not exclusivity Relationship to Other Documents Complements Conceptual Overview Clarifies interpretation of Pipeline Overview Does not describe execution mechanics or code structure Should be read before assuming incorrect behavior","title":"Ambiguity in Aruuz"},{"location":"guides/ambiguity/#ambiguity-in-aruuz-nigar","text":"This document is intended to clarify interpretation of results rather than engine mechanics.","title":"Ambiguity in Aruuz Nigar"},{"location":"guides/ambiguity/#purpose-of-this-document","text":"Explain why ambiguity is inherent in Urdu ar\u016bz Clarify how and where ambiguity arises in Aruuz Nigar Distinguish expected ambiguity from genuine limitations Help users interpret results correctly and confidently","title":"Purpose of This Document"},{"location":"guides/ambiguity/#why-ambiguity-exists-in-urdu-aruz","text":"Urdu ar\u016bz is based on pronunciation, not spelling Pronunciation varies by context, convention, and reader Classical prosody allows multiple valid readings of the same line Ambiguity is a property of the poetic system, not a computational artifact","title":"Why Ambiguity Exists in Urdu Ar\u016bz"},{"location":"guides/ambiguity/#ambiguity-as-a-design-principle","text":"Aruuz Nigar treats ambiguity as meaningful information The engine avoids forcing early decisions Multiple interpretations are preserved where rules permit Certainty is introduced only when structural evidence is sufficient","title":"Ambiguity as a Design Principle"},{"location":"guides/ambiguity/#types-of-ambiguity-encountered","text":"","title":"Types of Ambiguity Encountered"},{"location":"guides/ambiguity/#lexical-ambiguity-word-level","text":"A single word may admit multiple syllabic patterns Dictionary entries may contain variants Heuristic analysis may produce multiple valid outcomes Word-level ambiguity is common and expected","title":"Lexical Ambiguity (Word-Level)"},{"location":"guides/ambiguity/#contextual-ambiguity-inter-word","text":"Pronunciation may change based on neighboring words Classical prosodic rules introduce conditional variations Word joins and elisions can produce alternate rhythmic paths Contextual ambiguity may increase, not decrease, possibilities","title":"Contextual Ambiguity (Inter-Word)"},{"location":"guides/ambiguity/#metrical-ambiguity-line-level","text":"A complete rhythmic pattern may fit more than one meter Closely related meters may share structural prefixes Multiple meters may remain valid even after full analysis This reflects classical overlap, not analytical failure","title":"Metrical Ambiguity (Line-Level)"},{"location":"guides/ambiguity/#how-aruuz-nigar-handles-ambiguity","text":"","title":"How Aruuz Nigar Handles Ambiguity"},{"location":"guides/ambiguity/#intentional-over-generation","text":"The engine generates all plausible scansion possibilities No valid interpretations are discarded prematurely Over-generation ensures completeness of analysis","title":"Intentional Over-Generation"},{"location":"guides/ambiguity/#constraint-driven-pruning","text":"Invalid interpretations are eliminated by meter constraints Pruning occurs gradually as structure accumulates Only interpretations that violate prosodic rules are removed","title":"Constraint-Driven Pruning"},{"location":"guides/ambiguity/#late-resolution","text":"Ambiguity is resolved only after full line or multi-line context Word-level uncertainty is evaluated at meter level Decisions are postponed until meaningful comparison is possible","title":"Late Resolution"},{"location":"guides/ambiguity/#dominant-bahr-and-ambiguity","text":"","title":"Dominant Bahr and Ambiguity"},{"location":"guides/ambiguity/#what-dominant-means","text":"Dominance is a scoring-based preference It reflects consistency across related lines It does not imply absolute correctness","title":"What \u201cDominant\u201d Means"},{"location":"guides/ambiguity/#what-dominant-does-not-mean","text":"It does not mean alternate meters are wrong It does not eliminate all ambiguity in interpretation It does not override classical permissibility","title":"What Dominant Does Not Mean"},{"location":"guides/ambiguity/#when-ambiguity-is-expected","text":"Classical poetry with flexible pronunciation Lines with optional joins or elisions Meters with overlapping structural forms Words with well-known variant readings","title":"When Ambiguity Is Expected"},{"location":"guides/ambiguity/#when-ambiguity-may-indicate-a-limitation","text":"Rare or highly dialectal vocabulary Modern poetic forms outside classical ar\u016bz Incomplete lexical coverage Known unsupported or weakly supported meters","title":"When Ambiguity May Indicate a Limitation"},{"location":"guides/ambiguity/#how-users-should-interpret-results","text":"Multiple results should be read as interpretive space Human judgment remains essential in choosing among alternatives Consistency across lines is more significant than isolated matches Ambiguity should be explored, not dismissed","title":"How Users Should Interpret Results"},{"location":"guides/ambiguity/#common-misconceptions","text":"","title":"Common Misconceptions"},{"location":"guides/ambiguity/#more-results-mean-lower-confidence","text":"False: multiple results often indicate legitimate flexibility","title":"\u201cMore results mean lower confidence\u201d"},{"location":"guides/ambiguity/#there-must-be-exactly-one-correct-scansion","text":"False: classical ar\u016bz permits multiple valid readings","title":"\u201cThere must be exactly one correct scansion\u201d"},{"location":"guides/ambiguity/#dominant-bahr-is-the-only-correct-answer","text":"False: dominance reflects preference, not exclusivity","title":"\u201cDominant bahr is the only correct answer\u201d"},{"location":"guides/ambiguity/#relationship-to-other-documents","text":"Complements Conceptual Overview Clarifies interpretation of Pipeline Overview Does not describe execution mechanics or code structure Should be read before assuming incorrect behavior","title":"Relationship to Other Documents"},{"location":"guides/overview/","text":"Aruuz Nigar \u2014 Conceptual Overview This document is intended as a conceptual introduction for advanced users and developers. Purpose and Scope Provide a systematic way to analyze the meter of Urdu poetry Make classical ar\u016bz concepts accessible through computation Serve both as a learning aid and an analytical tool Focus on correctness, explainability, and openness rather than speed or polish What Aruuz Nigar Does Accepts Urdu poetic text as input Infers possible taqti patterns for each line Matches inferred patterns against known bahrs Identifies one dominant meter across related lines when possible Preserves ambiguity instead of forcing a single interpretation What Aruuz Nigar Does Not Do It does not \u201ccorrect\u201d poetry or judge poetic quality It does not assume a single universally correct taqti It does not attempt free-verse scansion It does not replace human understanding of ar\u016bz Core Concepts Aruuz as a Rule-Based System Urdu ar\u016bz follows structured prosodic rules These rules admit flexibility and context-dependent variation Aruuz Nigar encodes rules explicitly rather than statistically Heuristics are used only where rules permit ambiguity Words, Syllables, and Taqti Words are the smallest meaningful scansion units Each word may admit multiple syllabic interpretations Taqti represents syllable length as symbolic codes Word-level ambiguity is expected and preserved Meters (Bahr) and Feet (Rukn) A bahr is a structured pattern of feet Each foot represents a fixed rhythmic sequence Meters may admit multiple structural variants Matching is based on pattern compatibility, not exact string equality How the System Thinks Determinism and Heuristics Given the same input, the engine produces the same results Dictionary lookups are preferred where available Heuristics are applied only when lexical certainty is unavailable All heuristic decisions are traceable and explainable Ambiguity as a First-Class Outcome Multiple valid scans may coexist Ambiguity reflects real pronunciation and prosodic variation Suppressing ambiguity too early leads to incorrect results Resolution is deferred to higher analytical levels Over-Generation and Later Pruning The system deliberately generates more possibilities than needed Invalid paths are eliminated during meter matching Remaining candidates are scored and compared Only implausible interpretations are discarded, not uncertain ones Levels of Analysis Word-Level Analysis Assigns one or more scansion codes to each word Uses dictionary data, morphology, and heuristics Produces the highest degree of ambiguity Line-Level Analysis Combines word-level codes into complete rhythmic paths Applies contextual prosodic rules between words Matches complete paths against meter definitions Produces multiple possible meters per line if applicable Multi-Line (Sher) Resolution Assumes classical consistency of meter across related lines Scores meter compatibility across lines Selects the most consistent meter as dominant Retains per-line detail even after resolution Interpreting Results Multiple Valid Scans Multiple outputs do not imply error They reflect genuine alternative readings Human judgment remains essential in interpretation Dominant Bahr Selection Dominance is a scoring-based decision It reflects consistency, not absolute correctness Alternate meters are discarded only after comparison When and Why Results May Differ from Expectation Differences may arise from pronunciation assumptions Dialectal or poetic license can affect scansion Some classical ambiguities have no single resolution The system favors explainability over concealment Intended Users Poets and Advanced Readers To explore how lines fit classical meters To understand why a line scans in a particular way To study alternative readings and edge cases Developers and Researchers To study computational modeling of ar\u016bz To extend or experiment with scansion logic To use the engine in non-UI contexts Where to Go Next Pipeline Overview For a stage-by-stage conceptual walkthrough of the process Engine Execution Flow For class- and phase-level understanding of the core engine Deep Internal Data Flow For function-level tracing and contributor-oriented detail","title":"Conceptual Overview"},{"location":"guides/overview/#aruuz-nigar-conceptual-overview","text":"This document is intended as a conceptual introduction for advanced users and developers.","title":"Aruuz Nigar \u2014 Conceptual Overview"},{"location":"guides/overview/#purpose-and-scope","text":"Provide a systematic way to analyze the meter of Urdu poetry Make classical ar\u016bz concepts accessible through computation Serve both as a learning aid and an analytical tool Focus on correctness, explainability, and openness rather than speed or polish","title":"Purpose and Scope"},{"location":"guides/overview/#what-aruuz-nigar-does","text":"Accepts Urdu poetic text as input Infers possible taqti patterns for each line Matches inferred patterns against known bahrs Identifies one dominant meter across related lines when possible Preserves ambiguity instead of forcing a single interpretation","title":"What Aruuz Nigar Does"},{"location":"guides/overview/#what-aruuz-nigar-does-not-do","text":"It does not \u201ccorrect\u201d poetry or judge poetic quality It does not assume a single universally correct taqti It does not attempt free-verse scansion It does not replace human understanding of ar\u016bz","title":"What Aruuz Nigar Does Not Do"},{"location":"guides/overview/#core-concepts","text":"","title":"Core Concepts"},{"location":"guides/overview/#aruuz-as-a-rule-based-system","text":"Urdu ar\u016bz follows structured prosodic rules These rules admit flexibility and context-dependent variation Aruuz Nigar encodes rules explicitly rather than statistically Heuristics are used only where rules permit ambiguity","title":"Aruuz as a Rule-Based System"},{"location":"guides/overview/#words-syllables-and-taqti","text":"Words are the smallest meaningful scansion units Each word may admit multiple syllabic interpretations Taqti represents syllable length as symbolic codes Word-level ambiguity is expected and preserved","title":"Words, Syllables, and Taqti"},{"location":"guides/overview/#meters-bahr-and-feet-rukn","text":"A bahr is a structured pattern of feet Each foot represents a fixed rhythmic sequence Meters may admit multiple structural variants Matching is based on pattern compatibility, not exact string equality","title":"Meters (Bahr) and Feet (Rukn)"},{"location":"guides/overview/#how-the-system-thinks","text":"","title":"How the System Thinks"},{"location":"guides/overview/#determinism-and-heuristics","text":"Given the same input, the engine produces the same results Dictionary lookups are preferred where available Heuristics are applied only when lexical certainty is unavailable All heuristic decisions are traceable and explainable","title":"Determinism and Heuristics"},{"location":"guides/overview/#ambiguity-as-a-first-class-outcome","text":"Multiple valid scans may coexist Ambiguity reflects real pronunciation and prosodic variation Suppressing ambiguity too early leads to incorrect results Resolution is deferred to higher analytical levels","title":"Ambiguity as a First-Class Outcome"},{"location":"guides/overview/#over-generation-and-later-pruning","text":"The system deliberately generates more possibilities than needed Invalid paths are eliminated during meter matching Remaining candidates are scored and compared Only implausible interpretations are discarded, not uncertain ones","title":"Over-Generation and Later Pruning"},{"location":"guides/overview/#levels-of-analysis","text":"","title":"Levels of Analysis"},{"location":"guides/overview/#word-level-analysis","text":"Assigns one or more scansion codes to each word Uses dictionary data, morphology, and heuristics Produces the highest degree of ambiguity","title":"Word-Level Analysis"},{"location":"guides/overview/#line-level-analysis","text":"Combines word-level codes into complete rhythmic paths Applies contextual prosodic rules between words Matches complete paths against meter definitions Produces multiple possible meters per line if applicable","title":"Line-Level Analysis"},{"location":"guides/overview/#multi-line-sher-resolution","text":"Assumes classical consistency of meter across related lines Scores meter compatibility across lines Selects the most consistent meter as dominant Retains per-line detail even after resolution","title":"Multi-Line (Sher) Resolution"},{"location":"guides/overview/#interpreting-results","text":"","title":"Interpreting Results"},{"location":"guides/overview/#multiple-valid-scans","text":"Multiple outputs do not imply error They reflect genuine alternative readings Human judgment remains essential in interpretation","title":"Multiple Valid Scans"},{"location":"guides/overview/#dominant-bahr-selection","text":"Dominance is a scoring-based decision It reflects consistency, not absolute correctness Alternate meters are discarded only after comparison","title":"Dominant Bahr Selection"},{"location":"guides/overview/#when-and-why-results-may-differ-from-expectation","text":"Differences may arise from pronunciation assumptions Dialectal or poetic license can affect scansion Some classical ambiguities have no single resolution The system favors explainability over concealment","title":"When and Why Results May Differ from Expectation"},{"location":"guides/overview/#intended-users","text":"","title":"Intended Users"},{"location":"guides/overview/#poets-and-advanced-readers","text":"To explore how lines fit classical meters To understand why a line scans in a particular way To study alternative readings and edge cases","title":"Poets and Advanced Readers"},{"location":"guides/overview/#developers-and-researchers","text":"To study computational modeling of ar\u016bz To extend or experiment with scansion logic To use the engine in non-UI contexts","title":"Developers and Researchers"},{"location":"guides/overview/#where-to-go-next","text":"","title":"Where to Go Next"},{"location":"guides/overview/#pipeline-overview","text":"For a stage-by-stage conceptual walkthrough of the process","title":"Pipeline Overview"},{"location":"guides/overview/#engine-execution-flow","text":"For class- and phase-level understanding of the core engine","title":"Engine Execution Flow"},{"location":"guides/overview/#deep-internal-data-flow","text":"For function-level tracing and contributor-oriented detail","title":"Deep Internal Data Flow"},{"location":"guides/pipeline/","text":"Aruuz Nigar \u2014 Scansion Pipeline Overview This document assumes familiarity with basic ar\u016bz concepts and focuses on execution flow. Purpose of This Document Describe how Aruuz Nigar processes poetic text from input to scansion output Present the engine pipeline at a conceptual but accurate level Provide a mental model consistent with the actual execution flow Bridge high-level concepts and detailed internal documentation Pipeline at a Glance Input is processed through a sequence of constrained transformations Ambiguity is introduced early and resolved late Combination and pruning occur together, not as separate phases The pipeline is driven by structural constraints, not guesswork Stage 1: Input Normalization Raw poetic text is cleaned of punctuation and non-visible characters Characters are normalized to consistent forms Each line is treated as an independent analytical unit No rhythmic or metrical assumptions are made at this stage Stage 2: Tokenization into Words Each normalized line is split into lexical word units Word boundaries follow orthographic conventions Each word becomes a structured object for later analysis Diacritics, when present, are preserved as optional cues Stage 3: Word-Level Scansion Each word is analyzed in isolation Possible syllabic interpretations are inferred Long, short, and ambiguous syllables are represented symbolically Multiple scansion codes per word are expected and preserved Dictionary knowledge is preferred where available, heuristics fill gaps Stage 4: Contextual Prosodic Adjustment Inter-word prosodic rules are applied Pronunciation-dependent effects modify scansion possibilities Additional variants may be introduced based on context No scansion possibilities are discarded at this stage Stage 5: CodeTree Construction and Search Space Formation Word-level scansion variants are organized into a tree structure Each branch represents a complete rhythmic possibility for the line The tree encodes the full combinatorial search space implicitly No explicit Cartesian product of codes is materialized Stage 6: Tree Traversal and Meter Constraint Application The code tree is traversed depth-first Partial rhythmic paths are continuously checked against meter constraints Incompatible meters are eliminated as soon as constraints are violated Ambiguity is preserved where classical rules permit flexibility Matching and pruning occur simultaneously during traversal Stage 7: Line-Level Scansion Results Each surviving traversal path produces a complete line-level result Results include: Word-by-word taqti Complete rhythmic pattern One or more matching meters Multiple valid results per line may coexist Stage 8: Dominant Meter Resolution A classical assumption of meter consistency across related lines is applied Candidate meters are scored across all analyzed lines Structural consistency is prioritized over local or partial matches All non-dominant meters are explicitly discarded Stage 9: Final Output Output consists of structured scansion results Each result is traceable to the decisions made during the pipeline The engine makes no assumptions about presentation or formatting Consumers are free to render, visualize, or post-process results Key Design Properties of the Pipeline Deterministic Execution The same input always produces the same results No probabilistic or stochastic mechanisms are used Late Commitment Uncertainty is preserved until sufficient structural context exists Early decisions are avoided wherever possible Explainability Each transformation stage has a clear rationale Intermediate representations are inspectable Final results can be traced back through the pipeline Relationship to Other Documents This document explains what happens, and when It does not describe how individual functions are implemented For engine phase-level detail, see Pure Engine Execution Flow For function-level tracing, see Scansion Data Flow","title":"Scansion Pipeline"},{"location":"guides/pipeline/#aruuz-nigar-scansion-pipeline-overview","text":"This document assumes familiarity with basic ar\u016bz concepts and focuses on execution flow.","title":"Aruuz Nigar \u2014 Scansion Pipeline Overview"},{"location":"guides/pipeline/#purpose-of-this-document","text":"Describe how Aruuz Nigar processes poetic text from input to scansion output Present the engine pipeline at a conceptual but accurate level Provide a mental model consistent with the actual execution flow Bridge high-level concepts and detailed internal documentation","title":"Purpose of This Document"},{"location":"guides/pipeline/#pipeline-at-a-glance","text":"Input is processed through a sequence of constrained transformations Ambiguity is introduced early and resolved late Combination and pruning occur together, not as separate phases The pipeline is driven by structural constraints, not guesswork","title":"Pipeline at a Glance"},{"location":"guides/pipeline/#stage-1-input-normalization","text":"Raw poetic text is cleaned of punctuation and non-visible characters Characters are normalized to consistent forms Each line is treated as an independent analytical unit No rhythmic or metrical assumptions are made at this stage","title":"Stage 1: Input Normalization"},{"location":"guides/pipeline/#stage-2-tokenization-into-words","text":"Each normalized line is split into lexical word units Word boundaries follow orthographic conventions Each word becomes a structured object for later analysis Diacritics, when present, are preserved as optional cues","title":"Stage 2: Tokenization into Words"},{"location":"guides/pipeline/#stage-3-word-level-scansion","text":"Each word is analyzed in isolation Possible syllabic interpretations are inferred Long, short, and ambiguous syllables are represented symbolically Multiple scansion codes per word are expected and preserved Dictionary knowledge is preferred where available, heuristics fill gaps","title":"Stage 3: Word-Level Scansion"},{"location":"guides/pipeline/#stage-4-contextual-prosodic-adjustment","text":"Inter-word prosodic rules are applied Pronunciation-dependent effects modify scansion possibilities Additional variants may be introduced based on context No scansion possibilities are discarded at this stage","title":"Stage 4: Contextual Prosodic Adjustment"},{"location":"guides/pipeline/#stage-5-codetree-construction-and-search-space-formation","text":"Word-level scansion variants are organized into a tree structure Each branch represents a complete rhythmic possibility for the line The tree encodes the full combinatorial search space implicitly No explicit Cartesian product of codes is materialized","title":"Stage 5: CodeTree Construction and Search Space Formation"},{"location":"guides/pipeline/#stage-6-tree-traversal-and-meter-constraint-application","text":"The code tree is traversed depth-first Partial rhythmic paths are continuously checked against meter constraints Incompatible meters are eliminated as soon as constraints are violated Ambiguity is preserved where classical rules permit flexibility Matching and pruning occur simultaneously during traversal","title":"Stage 6: Tree Traversal and Meter Constraint Application"},{"location":"guides/pipeline/#stage-7-line-level-scansion-results","text":"Each surviving traversal path produces a complete line-level result Results include: Word-by-word taqti Complete rhythmic pattern One or more matching meters Multiple valid results per line may coexist","title":"Stage 7: Line-Level Scansion Results"},{"location":"guides/pipeline/#stage-8-dominant-meter-resolution","text":"A classical assumption of meter consistency across related lines is applied Candidate meters are scored across all analyzed lines Structural consistency is prioritized over local or partial matches All non-dominant meters are explicitly discarded","title":"Stage 8: Dominant Meter Resolution"},{"location":"guides/pipeline/#stage-9-final-output","text":"Output consists of structured scansion results Each result is traceable to the decisions made during the pipeline The engine makes no assumptions about presentation or formatting Consumers are free to render, visualize, or post-process results","title":"Stage 9: Final Output"},{"location":"guides/pipeline/#key-design-properties-of-the-pipeline","text":"","title":"Key Design Properties of the Pipeline"},{"location":"guides/pipeline/#deterministic-execution","text":"The same input always produces the same results No probabilistic or stochastic mechanisms are used","title":"Deterministic Execution"},{"location":"guides/pipeline/#late-commitment","text":"Uncertainty is preserved until sufficient structural context exists Early decisions are avoided wherever possible","title":"Late Commitment"},{"location":"guides/pipeline/#explainability","text":"Each transformation stage has a clear rationale Intermediate representations are inspectable Final results can be traced back through the pipeline","title":"Explainability"},{"location":"guides/pipeline/#relationship-to-other-documents","text":"This document explains what happens, and when It does not describe how individual functions are implemented For engine phase-level detail, see Pure Engine Execution Flow For function-level tracing, see Scansion Data Flow","title":"Relationship to Other Documents"},{"location":"guides/internals/engine-execution-flow/","text":"Aruuz Nigar \u2014 Pure Engine Execution Flow Scope This document describes the pure Aruuz scansion engine flow , excluding Flask, web routes, templates, or any UI concerns. It explains how input text is transformed into Aruuz (prosodic scansion) once it enters the engine layer , and how data flows across engine components until final scansion results are produced. This document assumes: - Input is already available as cleaned line strings - The caller is responsible for input/output presentation Engine Entry Point (Conceptual) Conceptual entry: List[str] \u2192 Aruuz Engine \u2192 List[scanOutput] In the current codebase, the engine is entered indirectly via Flask. Conceptually, however, the engine begins when: - A Scansion object is created - One or more Lines objects are added - scan_lines() is invoked Phase 1: Line \u2192 Words Lines Object Creation Class: Lines Responsibility: - Convert a raw line string into a structured list of words - Perform text cleaning and normalization Flow: 1. Clean punctuation and zero-width characters 2. Split line into word tokens 3. Normalize word forms 4. Create Words objects Output: - Lines.original_line - Lines.words_list: List[Words] At this stage, no scansion logic exists . The engine is still purely lexical. Phase 2: Engine Initialization Scansion Object Class: Scansion Responsibility: - Maintain engine-wide state - Coordinate scansion phases - Provide access to database lookup Key State: - lst_lines : all lines to be scanned - word_lookup : database interface (optional) - Mode flags: free_verse , fuzzy No computation occurs here beyond setup. Phase 3: Line Registration Adding Lines Method: Scansion.add_line() Responsibility: - Register Lines objects for later processing This stage merely accumulates input; no scansion is performed yet. Phase 4: Global Scan Invocation scan_lines() Method: Scansion.scan_lines() Responsibility: - Drive the full scansion process - Aggregate results across all lines High-level flow: 1. Iterate through all registered lines 2. Scan each line independently 3. Collect all scan results 4. Select dominant meter (crunch) Phase 5: Single-Line Scansion scan_line() This is the core engine pipeline for a single poetic line. Step 5.1: Word \u2192 Code Assignment Method: Scansion.word_code() For each word: 1. If codes already exist, skip 2. Attempt database lookup 3. If found: - Convert stored taqti to codes - Attach variations if marked is_varied 4. If not found: - Apply heuristic syllable analysis Output: - Each Words object now contains one or more scansion codes This step transforms textual words into symbolic rhythm units . Step 5.2: Contextual Word Adjustments After raw codes are assigned, inter-word rules are applied: Al (\u0627\u0644) handling Izafat handling Ataf (\u0648) handling Word grafting (\u0648\u0635\u0627\u0644 \u0627\u0644\u0641) These rules: - Modify word codes - Introduce alternative code paths - Reflect pronunciation-dependent scansion behavior At the end of this step, ambiguity is fully materialized. Phase 6: Code Combination Explosion CodeTree Construction Class: CodeTree Responsibility: - Represent all possible code combinations for the line Concept: - Each word may have multiple codes - Each code introduces a branch - The tree encodes the Cartesian product of possibilities This transforms linear code lists into a search space . Phase 7: Meter Matching Tree Traversal Method: CodeTree.find_meter() Responsibility: - Traverse all valid code paths - Match each path against known meter patterns Key Behavior: - x syllables act as wildcards - PatternTree expands ambiguous matches - Multiple meters may match a single path Output: - scanPath objects containing: - Concrete code sequences - Matching meter indices Phase 8: scanPath \u2192 scanOutput Each valid scan path is converted into a human-meaningful result. scanOutput contains: - Word-by-word taqti - Full scansion code - Meter name - Feet breakdown At this point, scansion is fully resolved for the line . Phase 9: Cross-Line Consolidation crunch() Responsibility: - Enforce the classical assumption of a dominant meter - Score meter consistency across lines - Discard non-dominant meters This step transforms multiple local truths into a global poetic interpretation . Phase 10: Engine Output Final Output: List[scanOutput] Each scanOutput represents: - One line - One meter - Fully resolved Aruuz scansion The engine does no formatting, rendering, or UI decisions . Conceptual Summary Lines (text) \u2193 Words (lexical units) \u2193 Codes (= - x) \u2193 CodeTree (combinatorial space) \u2193 scanPath (valid rhythmic paths) \u2193 scanOutput (metrical meaning) End of Pure Engine Flow Document","title":"Engine Execution Flow"},{"location":"guides/internals/engine-execution-flow/#aruuz-nigar-pure-engine-execution-flow","text":"","title":"Aruuz Nigar \u2014 Pure Engine Execution Flow"},{"location":"guides/internals/engine-execution-flow/#scope","text":"This document describes the pure Aruuz scansion engine flow , excluding Flask, web routes, templates, or any UI concerns. It explains how input text is transformed into Aruuz (prosodic scansion) once it enters the engine layer , and how data flows across engine components until final scansion results are produced. This document assumes: - Input is already available as cleaned line strings - The caller is responsible for input/output presentation","title":"Scope"},{"location":"guides/internals/engine-execution-flow/#engine-entry-point-conceptual","text":"Conceptual entry: List[str] \u2192 Aruuz Engine \u2192 List[scanOutput] In the current codebase, the engine is entered indirectly via Flask. Conceptually, however, the engine begins when: - A Scansion object is created - One or more Lines objects are added - scan_lines() is invoked","title":"Engine Entry Point (Conceptual)"},{"location":"guides/internals/engine-execution-flow/#phase-1-line-words","text":"","title":"Phase 1: Line \u2192 Words"},{"location":"guides/internals/engine-execution-flow/#lines-object-creation","text":"Class: Lines Responsibility: - Convert a raw line string into a structured list of words - Perform text cleaning and normalization Flow: 1. Clean punctuation and zero-width characters 2. Split line into word tokens 3. Normalize word forms 4. Create Words objects Output: - Lines.original_line - Lines.words_list: List[Words] At this stage, no scansion logic exists . The engine is still purely lexical.","title":"Lines Object Creation"},{"location":"guides/internals/engine-execution-flow/#phase-2-engine-initialization","text":"","title":"Phase 2: Engine Initialization"},{"location":"guides/internals/engine-execution-flow/#scansion-object","text":"Class: Scansion Responsibility: - Maintain engine-wide state - Coordinate scansion phases - Provide access to database lookup Key State: - lst_lines : all lines to be scanned - word_lookup : database interface (optional) - Mode flags: free_verse , fuzzy No computation occurs here beyond setup.","title":"Scansion Object"},{"location":"guides/internals/engine-execution-flow/#phase-3-line-registration","text":"","title":"Phase 3: Line Registration"},{"location":"guides/internals/engine-execution-flow/#adding-lines","text":"Method: Scansion.add_line() Responsibility: - Register Lines objects for later processing This stage merely accumulates input; no scansion is performed yet.","title":"Adding Lines"},{"location":"guides/internals/engine-execution-flow/#phase-4-global-scan-invocation","text":"","title":"Phase 4: Global Scan Invocation"},{"location":"guides/internals/engine-execution-flow/#scan_lines","text":"Method: Scansion.scan_lines() Responsibility: - Drive the full scansion process - Aggregate results across all lines High-level flow: 1. Iterate through all registered lines 2. Scan each line independently 3. Collect all scan results 4. Select dominant meter (crunch)","title":"scan_lines()"},{"location":"guides/internals/engine-execution-flow/#phase-5-single-line-scansion","text":"","title":"Phase 5: Single-Line Scansion"},{"location":"guides/internals/engine-execution-flow/#scan_line","text":"This is the core engine pipeline for a single poetic line.","title":"scan_line()"},{"location":"guides/internals/engine-execution-flow/#step-51-word-code-assignment","text":"Method: Scansion.word_code() For each word: 1. If codes already exist, skip 2. Attempt database lookup 3. If found: - Convert stored taqti to codes - Attach variations if marked is_varied 4. If not found: - Apply heuristic syllable analysis Output: - Each Words object now contains one or more scansion codes This step transforms textual words into symbolic rhythm units .","title":"Step 5.1: Word \u2192 Code Assignment"},{"location":"guides/internals/engine-execution-flow/#step-52-contextual-word-adjustments","text":"After raw codes are assigned, inter-word rules are applied: Al (\u0627\u0644) handling Izafat handling Ataf (\u0648) handling Word grafting (\u0648\u0635\u0627\u0644 \u0627\u0644\u0641) These rules: - Modify word codes - Introduce alternative code paths - Reflect pronunciation-dependent scansion behavior At the end of this step, ambiguity is fully materialized.","title":"Step 5.2: Contextual Word Adjustments"},{"location":"guides/internals/engine-execution-flow/#phase-6-code-combination-explosion","text":"","title":"Phase 6: Code Combination Explosion"},{"location":"guides/internals/engine-execution-flow/#codetree-construction","text":"Class: CodeTree Responsibility: - Represent all possible code combinations for the line Concept: - Each word may have multiple codes - Each code introduces a branch - The tree encodes the Cartesian product of possibilities This transforms linear code lists into a search space .","title":"CodeTree Construction"},{"location":"guides/internals/engine-execution-flow/#phase-7-meter-matching","text":"","title":"Phase 7: Meter Matching"},{"location":"guides/internals/engine-execution-flow/#tree-traversal","text":"Method: CodeTree.find_meter() Responsibility: - Traverse all valid code paths - Match each path against known meter patterns Key Behavior: - x syllables act as wildcards - PatternTree expands ambiguous matches - Multiple meters may match a single path Output: - scanPath objects containing: - Concrete code sequences - Matching meter indices","title":"Tree Traversal"},{"location":"guides/internals/engine-execution-flow/#phase-8-scanpath-scanoutput","text":"Each valid scan path is converted into a human-meaningful result. scanOutput contains: - Word-by-word taqti - Full scansion code - Meter name - Feet breakdown At this point, scansion is fully resolved for the line .","title":"Phase 8: scanPath \u2192 scanOutput"},{"location":"guides/internals/engine-execution-flow/#phase-9-cross-line-consolidation","text":"","title":"Phase 9: Cross-Line Consolidation"},{"location":"guides/internals/engine-execution-flow/#crunch","text":"Responsibility: - Enforce the classical assumption of a dominant meter - Score meter consistency across lines - Discard non-dominant meters This step transforms multiple local truths into a global poetic interpretation .","title":"crunch()"},{"location":"guides/internals/engine-execution-flow/#phase-10-engine-output","text":"Final Output: List[scanOutput] Each scanOutput represents: - One line - One meter - Fully resolved Aruuz scansion The engine does no formatting, rendering, or UI decisions .","title":"Phase 10: Engine Output"},{"location":"guides/internals/engine-execution-flow/#conceptual-summary","text":"Lines (text) \u2193 Words (lexical units) \u2193 Codes (= - x) \u2193 CodeTree (combinatorial space) \u2193 scanPath (valid rhythmic paths) \u2193 scanOutput (metrical meaning) End of Pure Engine Flow Document","title":"Conceptual Summary"},{"location":"guides/internals/scansion-data-flow/","text":"Scansion Data Flow Documented flow for taking an Urdu sher (two-line couplet) and determining the dominant bahr (meter) using the Python scansion engine. 1. High-Level Overview Input : Sher text (two lines separated by newline). Output : Dominant bahr name plus supporting scansion metadata per line. Major stages : Line cleaning & tokenization. Word-level scansion code assignment. Contextual prosodic adjustments. Code tree construction. Meter matching & result generation per line. Dominant bahr resolution across both lines. 2. Detailed Flow Each subsection lists what happens , the function , and the file (with representative line ranges) responsible for the transformation. Stage 1 \u2014 Sher Input \u2192 Lines objects What : Split the sher into separate lines, remove punctuation, normalize characters, and instantiate Lines . Functions : Lines.__init__() \u2014 python/aruuz/models.py L184-L242 clean_line() / clean_word() / handle_noon_followed_by_stop() \u2014 python/aruuz/utils/text.py Notes : clean_line() strips punctuation and zero-width chars. Regex r'[, ]+' splits into tokens; Noon+stop clusters are split. Each token becomes a Words object with diacritics removed via remove_araab() . Stage 2 \u2014 Word Objects \u2192 Initial Codes What : Assign scansion codes ( = , - , x , combinations) to each word via DB lookup plus heuristics. Functions : WordScansionAssigner.assign_code_to_word() \u2014 python/aruuz/scansion/word_scansion_assigner.py L36-L86 WordLookup.find_word() \u2014 python/aruuz/database/word_lookup.py compute_scansion() \u2014 python/aruuz/scansion/code_assignment.py L20-L119 Length scanners ( length_one_scan() \u2026 length_five_scan() ) \u2014 python/aruuz/scansion/length_scanners.py Notes : Strategy 1: Database tables ( exceptions , mastertable , variations , Plurals ) provide taqti strings which convert to codes. Strategy 2: Heuristics derive syllable lengths when DB misses. Strategy 3: _split_compound_word() attempts to combine DB + heuristic halves; stores Cartesian products of codes/muarrab. Stage 3 \u2014 Contextual Prosodic Rules What : Modify codes based on neighboring words and prosodic conventions. Function : ProsodicRules.apply_rules() with helpers for Al, Izafat, Ataf, grafting \u2014 python/aruuz/scansion/prosodic_rules.py Key behaviours : Al (\u0627\u0644) : If next word starts with \u201c\u0627\u0644\u201d, extend previous code to absorb the definite article. Izafat (\u0627\u0636\u0627\u0641\u062a) : Adjust endings when zer/izafat markers appear. Ataf (\u0639\u0637\u0641) : Handle conjunction \u201c\u0648\u201d by merging with previous word\u2019s cadence. Word grafting : When a consonant-ending word joins a following \u0627/\u0622 word, push alternative codes into word.taqti_word_graft . For each affected Words instance, append human-readable messages to prosodic_transformation_steps describing these contextual adjustments. Stage 4 \u2014 Code Tree Construction What : Build a tree representing all possible code sequences for the line. Function : CodeTree.build_from_line() \u2014 python/aruuz/tree/code_tree.py L98-L158 Notes : Root node is synthetic ( code=\"root\" ). For each word, every unique entry in word.code and word.taqti_word_graft becomes a branch ( codeLocation node). Children share word indices to cover multiple pronunciations/variants. Stage 5 \u2014 Meter Pattern Matching (per line) What : Traverse the code tree, prune codes against meter definitions, and emit matching paths. Functions : CodeTree.find_meter() and _traverse() \u2014 python/aruuz/tree/code_tree.py ~L473-L1019 _is_match() \u2014 compares partial code vs. meter templates (handles '+' , '~' , 'x' ) \u2014 code_tree.py L162-L241 _check_code_length() \u2014 validates final code length against meter variations \u2014 code_tree.py L341-L412 Hindi/Zamzama special handling via PatternTree \u2014 python/aruuz/tree/pattern_tree.py Notes : For each node, tentative code string is compared to all candidate meters; non-matching meters drop off. At leaves, surviving meter indices become part of a scanPath . Stage 6 \u2014 scanPath \u2192 LineScansionResult What : Convert each successful path into human-readable scansion info. Function : MeterMatcher.match_line_to_meters() \u2014 python/aruuz/scansion/meter_matching.py L81-L313 Notes : Extracts ordered Words references via scanPath.location . Builds word_taqti , full_code , and interprets meter index into Urdu rukn names using aruuz.meters . Returns LineScansionResult list per line (one entry per matched meter). Stage 7 \u2014 Dominant Bahr Resolution (across lines) What : Combine both misra results and choose the dominant meter. Functions : MeterResolver.resolve_dominant_meter() \u2014 python/aruuz/scansion/scoring.py L151-L220 MeterResolver.calculate_score() \u2014 python/aruuz/scansion/scoring.py L24-L92 Notes : Collect unique meter names from all line results. For each meter, sum ordered-foot matches produced by calculate_score() (which checks each variant from aruuz.meters via meter_index() and afail() ). Highest total wins; only LineScansionResult objects for that meter are returned/flagged as dominant. 3. Data & Code Representations Symbols : = long syllable (2 morae). - short syllable (1 mora). x ambiguous syllable (short or long). Core classes (from python/aruuz/models.py ): Words : stores word , code[] , taqti[] , muarrab[] , taqti_word_graft[] , flags ( is_varied , modified ), and two explanation lists: scansion_generation_steps (base code generation) and prosodic_transformation_steps (contextual prosodic changes). Lines : wraps original_line and words_list . codeLocation : tree node metadata ( code , word_ref , code_ref , word ). scanPath : ordered codeLocation list + surviving meter indices. LineScansionResult : final per-line output (meter name, feet string/list, word codes, dominance flag). 4. File Reference Table Stage Function(s) File Input cleaning & line split Lines.__init__() ; clean_line() , clean_word() python/aruuz/models.py ; python/aruuz/utils/text.py Word code assignment WordScansionAssigner.assign_code_to_word() ; WordLookup.find_word() ; compute_scansion() python/aruuz/scansion/word_scansion_assigner.py ; python/aruuz/database/word_lookup.py ; python/aruuz/scansion/code_assignment.py Prosodic adjustments ProsodicRules.apply_rules() python/aruuz/scansion/prosodic_rules.py Tree building CodeTree.build_from_line() python/aruuz/tree/code_tree.py Meter traversal CodeTree.find_meter() / _traverse() / _is_match() python/aruuz/tree/code_tree.py scanPath \u2192 result MeterMatcher.match_line_to_meters() python/aruuz/scansion/meter_matching.py Dominant meter MeterResolver.resolve_dominant_meter() ; calculate_score() python/aruuz/scansion/scoring.py 5. Flow Diagram See scansion_data_flow.mmd for a Mermaid flowchart mirroring the stages above.","title":"Scansion Data Flow"},{"location":"guides/internals/scansion-data-flow/#scansion-data-flow","text":"Documented flow for taking an Urdu sher (two-line couplet) and determining the dominant bahr (meter) using the Python scansion engine.","title":"Scansion Data Flow"},{"location":"guides/internals/scansion-data-flow/#1-high-level-overview","text":"Input : Sher text (two lines separated by newline). Output : Dominant bahr name plus supporting scansion metadata per line. Major stages : Line cleaning & tokenization. Word-level scansion code assignment. Contextual prosodic adjustments. Code tree construction. Meter matching & result generation per line. Dominant bahr resolution across both lines.","title":"1. High-Level Overview"},{"location":"guides/internals/scansion-data-flow/#2-detailed-flow","text":"Each subsection lists what happens , the function , and the file (with representative line ranges) responsible for the transformation.","title":"2. Detailed Flow"},{"location":"guides/internals/scansion-data-flow/#stage-1-sher-input-lines-objects","text":"What : Split the sher into separate lines, remove punctuation, normalize characters, and instantiate Lines . Functions : Lines.__init__() \u2014 python/aruuz/models.py L184-L242 clean_line() / clean_word() / handle_noon_followed_by_stop() \u2014 python/aruuz/utils/text.py Notes : clean_line() strips punctuation and zero-width chars. Regex r'[, ]+' splits into tokens; Noon+stop clusters are split. Each token becomes a Words object with diacritics removed via remove_araab() .","title":"Stage 1 \u2014 Sher Input \u2192 Lines objects"},{"location":"guides/internals/scansion-data-flow/#stage-2-word-objects-initial-codes","text":"What : Assign scansion codes ( = , - , x , combinations) to each word via DB lookup plus heuristics. Functions : WordScansionAssigner.assign_code_to_word() \u2014 python/aruuz/scansion/word_scansion_assigner.py L36-L86 WordLookup.find_word() \u2014 python/aruuz/database/word_lookup.py compute_scansion() \u2014 python/aruuz/scansion/code_assignment.py L20-L119 Length scanners ( length_one_scan() \u2026 length_five_scan() ) \u2014 python/aruuz/scansion/length_scanners.py Notes : Strategy 1: Database tables ( exceptions , mastertable , variations , Plurals ) provide taqti strings which convert to codes. Strategy 2: Heuristics derive syllable lengths when DB misses. Strategy 3: _split_compound_word() attempts to combine DB + heuristic halves; stores Cartesian products of codes/muarrab.","title":"Stage 2 \u2014 Word Objects \u2192 Initial Codes"},{"location":"guides/internals/scansion-data-flow/#stage-3-contextual-prosodic-rules","text":"What : Modify codes based on neighboring words and prosodic conventions. Function : ProsodicRules.apply_rules() with helpers for Al, Izafat, Ataf, grafting \u2014 python/aruuz/scansion/prosodic_rules.py Key behaviours : Al (\u0627\u0644) : If next word starts with \u201c\u0627\u0644\u201d, extend previous code to absorb the definite article. Izafat (\u0627\u0636\u0627\u0641\u062a) : Adjust endings when zer/izafat markers appear. Ataf (\u0639\u0637\u0641) : Handle conjunction \u201c\u0648\u201d by merging with previous word\u2019s cadence. Word grafting : When a consonant-ending word joins a following \u0627/\u0622 word, push alternative codes into word.taqti_word_graft . For each affected Words instance, append human-readable messages to prosodic_transformation_steps describing these contextual adjustments.","title":"Stage 3 \u2014 Contextual Prosodic Rules"},{"location":"guides/internals/scansion-data-flow/#stage-4-code-tree-construction","text":"What : Build a tree representing all possible code sequences for the line. Function : CodeTree.build_from_line() \u2014 python/aruuz/tree/code_tree.py L98-L158 Notes : Root node is synthetic ( code=\"root\" ). For each word, every unique entry in word.code and word.taqti_word_graft becomes a branch ( codeLocation node). Children share word indices to cover multiple pronunciations/variants.","title":"Stage 4 \u2014 Code Tree Construction"},{"location":"guides/internals/scansion-data-flow/#stage-5-meter-pattern-matching-per-line","text":"What : Traverse the code tree, prune codes against meter definitions, and emit matching paths. Functions : CodeTree.find_meter() and _traverse() \u2014 python/aruuz/tree/code_tree.py ~L473-L1019 _is_match() \u2014 compares partial code vs. meter templates (handles '+' , '~' , 'x' ) \u2014 code_tree.py L162-L241 _check_code_length() \u2014 validates final code length against meter variations \u2014 code_tree.py L341-L412 Hindi/Zamzama special handling via PatternTree \u2014 python/aruuz/tree/pattern_tree.py Notes : For each node, tentative code string is compared to all candidate meters; non-matching meters drop off. At leaves, surviving meter indices become part of a scanPath .","title":"Stage 5 \u2014 Meter Pattern Matching (per line)"},{"location":"guides/internals/scansion-data-flow/#stage-6-scanpath-linescansionresult","text":"What : Convert each successful path into human-readable scansion info. Function : MeterMatcher.match_line_to_meters() \u2014 python/aruuz/scansion/meter_matching.py L81-L313 Notes : Extracts ordered Words references via scanPath.location . Builds word_taqti , full_code , and interprets meter index into Urdu rukn names using aruuz.meters . Returns LineScansionResult list per line (one entry per matched meter).","title":"Stage 6 \u2014 scanPath \u2192 LineScansionResult"},{"location":"guides/internals/scansion-data-flow/#stage-7-dominant-bahr-resolution-across-lines","text":"What : Combine both misra results and choose the dominant meter. Functions : MeterResolver.resolve_dominant_meter() \u2014 python/aruuz/scansion/scoring.py L151-L220 MeterResolver.calculate_score() \u2014 python/aruuz/scansion/scoring.py L24-L92 Notes : Collect unique meter names from all line results. For each meter, sum ordered-foot matches produced by calculate_score() (which checks each variant from aruuz.meters via meter_index() and afail() ). Highest total wins; only LineScansionResult objects for that meter are returned/flagged as dominant.","title":"Stage 7 \u2014 Dominant Bahr Resolution (across lines)"},{"location":"guides/internals/scansion-data-flow/#3-data-code-representations","text":"Symbols : = long syllable (2 morae). - short syllable (1 mora). x ambiguous syllable (short or long). Core classes (from python/aruuz/models.py ): Words : stores word , code[] , taqti[] , muarrab[] , taqti_word_graft[] , flags ( is_varied , modified ), and two explanation lists: scansion_generation_steps (base code generation) and prosodic_transformation_steps (contextual prosodic changes). Lines : wraps original_line and words_list . codeLocation : tree node metadata ( code , word_ref , code_ref , word ). scanPath : ordered codeLocation list + surviving meter indices. LineScansionResult : final per-line output (meter name, feet string/list, word codes, dominance flag).","title":"3. Data &amp; Code Representations"},{"location":"guides/internals/scansion-data-flow/#4-file-reference-table","text":"Stage Function(s) File Input cleaning & line split Lines.__init__() ; clean_line() , clean_word() python/aruuz/models.py ; python/aruuz/utils/text.py Word code assignment WordScansionAssigner.assign_code_to_word() ; WordLookup.find_word() ; compute_scansion() python/aruuz/scansion/word_scansion_assigner.py ; python/aruuz/database/word_lookup.py ; python/aruuz/scansion/code_assignment.py Prosodic adjustments ProsodicRules.apply_rules() python/aruuz/scansion/prosodic_rules.py Tree building CodeTree.build_from_line() python/aruuz/tree/code_tree.py Meter traversal CodeTree.find_meter() / _traverse() / _is_match() python/aruuz/tree/code_tree.py scanPath \u2192 result MeterMatcher.match_line_to_meters() python/aruuz/scansion/meter_matching.py Dominant meter MeterResolver.resolve_dominant_meter() ; calculate_score() python/aruuz/scansion/scoring.py","title":"4. File Reference Table"},{"location":"guides/internals/scansion-data-flow/#5-flow-diagram","text":"See scansion_data_flow.mmd for a Mermaid flowchart mirroring the stages above.","title":"5. Flow Diagram"}]}